{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Voice Cloning Experiment â€” Reproducible Notebook\n",
        "Objective: reproduce a voice cloning pipeline, log errors, track time and GPU usage, and produce a 30s original vs cloned sample.\n",
        "\n"
      ],
      "metadata": {
        "id": "til7lTy_37Jz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Core dependencies (examples; prefer lightweight, well-known repos)\n",
        "!pip install numpy scipy matplotlib librosa soundfile webrtcvad tqdm\n",
        "# For deep learning\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "# Optional: use a maintained voice cloning repo (e.g., Coqui TTS or Real-Time-Voice-Cloning forks)\n",
        "# Here we clone a stable implementation. Replace with your preferred repo.\n",
        "!git clone https://github.com/CorentinJ/Real-Time-Voice-Cloning.git /content/voiceclone\n",
        "%cd /content/voiceclone\n",
        "!pip install -r requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAYXdNOyhmN8",
        "outputId": "fdfc5d4d-176a-49c4-b893-643d8585785a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.12/dist-packages (0.11.0)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.12/dist-packages (0.13.1)\n",
            "Requirement already satisfied: webrtcvad in /usr/local/lib/python3.12/dist-packages (2.0.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.12/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: scikit-learn>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.5.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (4.15.0)\n",
            "Requirement already satisfied: lazy_loader>=0.1 in /usr/local/lib/python3.12/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.12/dist-packages (from librosa) (1.1.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (4.3.8)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa) (2.32.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2025.8.3)\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "fatal: destination path '/content/voiceclone' already exists and is not an empty directory.\n",
            "/content/voiceclone\n",
            "Collecting inflect==5.3.0 (from -r requirements.txt (line 1))\n",
            "  Using cached inflect-5.3.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting librosa==0.8.1 (from -r requirements.txt (line 2))\n",
            "  Using cached librosa-0.8.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Collecting matplotlib==3.5.1 (from -r requirements.txt (line 3))\n",
            "  Using cached matplotlib-3.5.1.tar.gz (35.3 MB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy==1.20.3 (from -r requirements.txt (line 4))\n",
            "  Using cached numpy-1.20.3.zip (7.8 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: Exception:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "             ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/commands/install.py\", line 377, in run\n",
            "    requirement_set = resolver.resolve(\n",
            "                      ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/resolver.py\", line 95, in resolve\n",
            "    result = self._result = resolver.resolve(\n",
            "                            ^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 546, in resolve\n",
            "    state = resolution.resolve(requirements, max_rounds=max_rounds)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 397, in resolve\n",
            "    self._add_to_criteria(self.state.criteria, r, parent=None)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/resolvelib/resolvers.py\", line 173, in _add_to_criteria\n",
            "    if not criterion.candidates:\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/resolvelib/structs.py\", line 156, in __bool__\n",
            "    return bool(self._sequence)\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 174, in __bool__\n",
            "    return any(self)\n",
            "           ^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 162, in <genexpr>\n",
            "    return (c for c in iterator if id(c) not in self._incompatible_ids)\n",
            "                       ^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/found_candidates.py\", line 53, in _iter_built\n",
            "    candidate = func()\n",
            "                ^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 185, in _make_candidate_from_link\n",
            "    base: Optional[BaseCandidate] = self._make_base_candidate_from_link(\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/factory.py\", line 231, in _make_base_candidate_from_link\n",
            "    self._link_candidate_cache[link] = LinkCandidate(\n",
            "                                       ^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 303, in __init__\n",
            "    super().__init__(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 158, in __init__\n",
            "    self.dist = self._prepare()\n",
            "                ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 235, in _prepare\n",
            "    dist = self._prepare_distribution()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/resolution/resolvelib/candidates.py\", line 314, in _prepare_distribution\n",
            "    return preparer.prepare_linked_requirement(self._ireq, parallel_builds=True)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/prepare.py\", line 527, in prepare_linked_requirement\n",
            "    return self._prepare_linked_requirement(req, parallel_builds)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/prepare.py\", line 642, in _prepare_linked_requirement\n",
            "    dist = _get_prepared_distribution(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/operations/prepare.py\", line 72, in _get_prepared_distribution\n",
            "    abstract_dist.prepare_distribution_metadata(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/distributions/sdist.py\", line 56, in prepare_distribution_metadata\n",
            "    self._install_build_reqs(finder)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/distributions/sdist.py\", line 126, in _install_build_reqs\n",
            "    build_reqs = self._get_build_requires_wheel()\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/distributions/sdist.py\", line 103, in _get_build_requires_wheel\n",
            "    return backend.get_requires_for_build_wheel()\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_internal/utils/misc.py\", line 709, in get_requires_for_build_wheel\n",
            "    return super().get_requires_for_build_wheel(config_settings=cs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/pyproject_hooks/_impl.py\", line 166, in get_requires_for_build_wheel\n",
            "    return self._call_hook('get_requires_for_build_wheel', {\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/pyproject_hooks/_impl.py\", line 321, in _call_hook\n",
            "    raise BackendUnavailable(data.get('traceback', ''))\n",
            "pip._vendor.pyproject_hooks._impl.BackendUnavailable: Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/pip/_vendor/pyproject_hooks/_in_process/_in_process.py\", line 77, in _build_backend\n",
            "    obj = import_module(mod_path)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1310, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
            "  File \"<frozen importlib._bootstrap>\", line 1387, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 999, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n",
            "  File \"/tmp/pip-build-env-_6bo4l_3/overlay/local/lib/python3.12/dist-packages/setuptools/__init__.py\", line 18, in <module>\n",
            "    from setuptools.extern.six import PY3, string_types\n",
            "ModuleNotFoundError: No module named 'setuptools.extern.six'\n",
            "\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# Create experiment directory\n",
        "!mkdir -p /content/drive/MyDrive/voice_cloning_experiment\n",
        "EXPERIMENT_DIR = \"/content/drive/MyDrive/voice_cloning_experiment\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YofOUiNuhmWv",
        "outputId": "f055b6b8-6dcb-425d-f402-8b950213d6d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: expected checkpoints for encoder, synthesizer, vocoder\n",
        "# Replace the URLs with checkpoint URLs you trust or upload them to Drive.\n",
        "ENCODER_CKPT = f\"{EXPERIMENT_DIR}/encoder.pt\"\n",
        "SYNTHESIZER_CKPT = f\"{EXPERIMENT_DIR}/synthesizer.pt\"\n",
        "VOCODER_CKPT = f\"{EXPERIMENT_DIR}/vocoder.pt\"\n",
        "\n",
        "print('Place pretrained checkpoints at:', EXPERIMENT_DIR)\n",
        "# If you have URLs, use wget here. Otherwise, upload to Drive manually."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHLcJtarhmcU",
        "outputId": "2e78c28c-0e2e-475e-9bb1-53263cd8d034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Place pretrained checkpoints at: /content/drive/MyDrive/voice_cloning_experiment\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time, os, json, traceback\n",
        "LOG_DIR = os.path.join(EXPERIMENT_DIR, \"logs\")\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "ERROR_LOG = os.path.join(LOG_DIR, \"error_log.jsonl\")\n",
        "TIMING_LOG = os.path.join(LOG_DIR, \"timing_log.jsonl\")\n",
        "\n",
        "def log_error(stage, err):\n",
        "    entry = {\n",
        "        \"timestamp\": time.time(),\n",
        "        \"stage\": stage,\n",
        "        \"error\": str(err),\n",
        "        \"traceback\": traceback.format_exc()\n",
        "    }\n",
        "    with open(ERROR_LOG, \"a\") as f:\n",
        "        f.write(json.dumps(entry)+\"\\n\")\n",
        "    print(\"Logged error:\", stage)\n",
        "\n",
        "def log_timing(stage, duration_seconds):\n",
        "    entry = { \"timestamp\": time.time(), \"stage\": stage, \"duration_s\": duration_seconds }\n",
        "    with open(TIMING_LOG, \"a\") as f:\n",
        "        f.write(json.dumps(entry)+\"\\n\")"
      ],
      "metadata": {
        "id": "JaDuiLmshmfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU availability and specs\n",
        "import torch, subprocess, json\n",
        "gpu_available = torch.cuda.is_available()\n",
        "gpu_name = torch.cuda.get_device_name(0) if gpu_available else \"CPU\"\n",
        "total_mem = torch.cuda.get_device_properties(0).total_memory if gpu_available else None\n",
        "print(\"GPU available:\", gpu_available, \"GPU name:\", gpu_name, \"Total mem:\", total_mem)\n",
        "# Log GPU info\n",
        "with open(os.path.join(LOG_DIR, \"gpu_info.json\"), \"w\") as f:\n",
        "    json.dump({\"gpu_available\": gpu_available, \"gpu_name\": gpu_name, \"total_mem\": total_mem}, f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgZICopAhmhv",
        "outputId": "040ee26b-6510-4a57-9f9a-38235e95b474"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU available: True GPU name: Tesla T4 Total mem: 15828320256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assumes you will upload a folder of WAVs for the target speaker and optionally a single original 30s sample to compare.\n",
        "DATA_DIR = os.path.join(EXPERIMENT_DIR, \"data\")\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "print(\"Upload your WAV files into:\", DATA_DIR)\n",
        "# example script to list files\n",
        "import glob\n",
        "wav_files = glob.glob(os.path.join(DATA_DIR,\"*.wav\"))\n",
        "print(\"Found wav files:\", len(wav_files))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtooTxoBhmkT",
        "outputId": "73392a28-3ffb-4ede-cc96-1ef534764171"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload your WAV files into: /content/drive/MyDrive/voice_cloning_experiment/data\n",
            "Found wav files: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example using librosa to load and resample to 22050 Hz, mono\n",
        "import librosa, soundfile as sf\n",
        "def preprocess_wav(src_path, dst_path, sr=22050):\n",
        "    y, _ = librosa.load(src_path, sr=sr, mono=True)\n",
        "    sf.write(dst_path, y, sr)\n",
        "# run on all files\n",
        "for i, src in enumerate(wav_files):\n",
        "    dst = os.path.join(DATA_DIR, f\"proc_{i}.wav\")\n",
        "    try:\n",
        "        preprocess_wav(src, dst)\n",
        "    except Exception as e:\n",
        "        log_error(\"preprocess_wav\", e)"
      ],
      "metadata": {
        "id": "2a-HdzGdhmmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# WARNING: full training requires heavy resources. Many experiments use pretrained models + fine-tune or synthesizer only.\n",
        "# Example pseudocode of fine-tuning the synthesizer (replace with repo-specific training commands).\n",
        "start = time.time()\n",
        "try:\n",
        "    # Placeholder: replace with actual training command from the cloned repo\n",
        "    # e.g., !python train_synth.py --data_dir /content/drive/MyDrive/voice_cloning_experiment/data ...\n",
        "    print(\"Run the repo-specific training command here; this cell is a placeholder.\")\n",
        "except Exception as e:\n",
        "    log_error(\"train\", e)\n",
        "finally:\n",
        "    log_timing(\"train\", time.time() - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pO_7ZxP5hmpO",
        "outputId": "46d6b1cc-e4fd-4f2a-c4a0-70eb149fe580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run the repo-specific training command here; this cell is a placeholder.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example inference flow (repo-specific): encode speaker, synthesize mel, vocode to waveform.\n",
        "start = time.time()\n",
        "try:\n",
        "    # Placeholder pseudocode; replace with repo inference functions.\n",
        "    # from encoder import inference as enc\n",
        "    # from synthesizer import synthesize\n",
        "    # from vocoder import infer_waveform\n",
        "    print(\"Run inference to synthesize a 30s sample. Use your text or original sample's content.\")\n",
        "except Exception as e:\n",
        "    log_error(\"inference\", e)\n",
        "finally:\n",
        "    log_timing(\"inference\", time.time() - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxpvE0b-hmrv",
        "outputId": "9c9068b5-26b8-4753-f00e-9d523ad8cb87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run inference to synthesize a 30s sample. Use your text or original sample's content.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save generated wav to results/audio_samples/cloned_30s.wav\n",
        "OUT_DIR = os.path.join(EXPERIMENT_DIR, \"results\", \"audio_samples\")\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "# Example: copy proc_0.wav to cloned sample path for placeholder\n",
        "import shutil\n",
        "try:\n",
        "    # Replace with the actual generated file path\n",
        "    generated_wav = os.path.join(DATA_DIR, \"proc_0.wav\")\n",
        "    cloned_path = os.path.join(OUT_DIR, \"cloned_30s.wav\")\n",
        "    shutil.copyfile(generated_wav, cloned_path)\n",
        "    print(\"Cloned sample saved to:\", cloned_path)\n",
        "except Exception as e:\n",
        "    log_error(\"save_cloned\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mewg2hRlaEy",
        "outputId": "419a8c44-8b62-4b58-babc-eb379ae1be21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logged error: save_cloned\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute basic objective metrics: SNR, PESQ (if installed), Mel-Cepstral distortion (MCD) stub\n",
        "import numpy as np\n",
        "def compute_snr(orig, synth):\n",
        "    import librosa\n",
        "    o, _ = librosa.load(orig, sr=22050, mono=True)\n",
        "    s, _ = librosa.load(synth, sr=22050, mono=True)\n",
        "    min_len = min(len(o), len(s))\n",
        "    o, s = o[:min_len], s[:min_len]\n",
        "    noise = o - s\n",
        "    snr = 10 * np.log10((o**2).sum() / (noise**2).sum() + 1e-9)\n",
        "    return snr\n",
        "try:\n",
        "    orig = os.path.join(DATA_DIR, \"proc_0.wav\")  # replace with true original 30s\n",
        "    synt = os.path.join(OUT_DIR, \"cloned_30s.wav\")\n",
        "    print(\"SNR (dB):\", compute_snr(orig, synt))\n",
        "except Exception as e:\n",
        "    log_error(\"objective_eval\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsX2Lq_6laLy",
        "outputId": "1c0a1d85-5104-415a-f0b5-2ec411d2fef4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logged error: objective_eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-149606168.py:5: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  o, _ = librosa.load(orig, sr=22050, mono=True)\n",
            "/usr/local/lib/python3.12/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Subjective Listening Test\n",
        "\n",
        "1. Prepare pairs: `original_30s.wav` and `cloned_30s.wav`.\n",
        "2. Randomize order for listeners; collect judgments for:\n",
        "   - Naturalness (1-5)\n",
        "   - Similarity to target speaker (1-5)\n",
        "   - Intelligibility (1-5)\n",
        "3. Use at least 5 listeners for a small test. Aggregate mean scores and standard deviation.\n"
      ],
      "metadata": {
        "id": "6Zrh-smgqGwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List outputs and create a zip to download\n",
        "!zip -r /content/voice_cloning_results.zip {EXPERIMENT_DIR}\n",
        "print(\"Zipped experiment folder:\", \"/content/voice_cloning_results.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMN0NPXalaOm",
        "outputId": "e99b3ad0-c77b-4bcc-c425-04c1940eff04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: content/drive/MyDrive/voice_cloning_experiment/ (stored 0%)\n",
            "updating: content/drive/MyDrive/voice_cloning_experiment/logs/ (stored 0%)\n",
            "updating: content/drive/MyDrive/voice_cloning_experiment/logs/gpu_info.json (deflated 8%)\n",
            "updating: content/drive/MyDrive/voice_cloning_experiment/logs/timing_log.jsonl (deflated 67%)\n",
            "updating: content/drive/MyDrive/voice_cloning_experiment/logs/error_log.jsonl (deflated 90%)\n",
            "updating: content/drive/MyDrive/voice_cloning_experiment/data/ (stored 0%)\n",
            "updating: content/drive/MyDrive/voice_cloning_experiment/results/ (stored 0%)\n",
            "updating: content/drive/MyDrive/voice_cloning_experiment/results/audio_samples/ (stored 0%)\n",
            "Zipped experiment folder: /content/voice_cloning_results.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(cfg):\n",
        "    probe = probe_resources()\n",
        "    log(\"probe\", probe)\n",
        "    try:\n",
        "        preprocess(cfg.data_dir, cfg.work_dir)\n",
        "        train_cfg = adapt_cfg_for_resources(cfg, probe)\n",
        "        train_model(train_cfg)\n",
        "        synth_wav = inference(cfg.eval_text, cfg.work_dir)\n",
        "        metrics = evaluate(cfg.original_wav, synth_wav)\n",
        "        package_artifacts(cfg.work_dir)\n",
        "    except Exception as e:\n",
        "        log_error(\"run_experiment\", e)\n",
        "        raise\n"
      ],
      "metadata": {
        "id": "_V-0jRdhqhkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adapt_cfg_for_resources(cfg, probe):\n",
        "    if probe.gpu_memory < 12*1024**2: # < 12GB\n",
        "        cfg.batch_size = max(1, cfg.batch_size // 4)\n",
        "        cfg.use_mixed_precision = True\n",
        "    return cfg"
      ],
      "metadata": {
        "id": "l9TvtYsmqhry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. How to produce the deliverables you requested\n",
        "\n",
        "Deliverable checklist & instructions\n",
        "\n",
        "GitHub repo with code\n",
        "\n",
        "Create repo locally:"
      ],
      "metadata": {
        "id": "8lMdv83664k3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir voice-cloning-experiment && cd voice-cloning-experiment\n",
        "!git init\n",
        "# create files per scaffold (README, colab notebook, src files)\n",
        "!git add .\n",
        "!git commit -m \"Initial experiment scaffold\"\n",
        "# create remote and push (replace with your own GitHub URL)\n",
        "!git remote add origin https://github.com/MujahidMalik819061/Voice-Cloning-Assignment.git\n",
        "!git push -u origin main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9xlrJEw6jJN",
        "outputId": "21e17586-99e5-4f5b-cc6f-6d157e72d8f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory â€˜voice-cloning-experimentâ€™: File exists\n",
            "Reinitialized existing Git repository in /content/voiceclone/.git/\n",
            "Author identity unknown\n",
            "\n",
            "*** Please tell me who you are.\n",
            "\n",
            "Run\n",
            "\n",
            "  git config --global user.email \"you@example.com\"\n",
            "  git config --global user.name \"Your Name\"\n",
            "\n",
            "to set your account's default identity.\n",
            "Omit --global to set the identity only in this repository.\n",
            "\n",
            "fatal: unable to auto-detect email address (got 'root@905b31e1d3e5.(none)')\n",
            "error: remote origin already exists.\n",
            "error: src refspec main does not match any\n",
            "\u001b[31merror: failed to push some refs to 'https://github.com/CorentinJ/Real-Time-Voice-Cloning.git'\n",
            "\u001b[m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open(os.path.join(LOG_DIR, 'error_log.jsonl')) as f:\n",
        "    entries = [json.loads(line) for line in f]\n",
        "# write summary to docs/error_summary.md"
      ],
      "metadata": {
        "id": "BL1SAHaR78lq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Example src/inference.py (skeleton)"
      ],
      "metadata": {
        "id": "9lS44kBB8QmQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "def load_models(encoder_path, syn_path, voc_path, device=\"cuda\"):\n",
        "    # repo-specific loading; this is a skeleton.\n",
        "    encoder = torch.load(encoder_path, map_location=device)\n",
        "    synthesizer = torch.load(syn_path, map_location=device)\n",
        "    vocoder = torch.load(voc_path, map_location=device)\n",
        "    return encoder, synthesizer, vocoder\n",
        "\n",
        "def synthesize_text(encoder, synthesizer, vocoder, speaker_wav, text, out_path):\n",
        "    # 1) Encode speaker\n",
        "    # 2) Synthesize mel from text + speaker embedding\n",
        "    # 3) Vocode mel to waveform\n",
        "    pass"
      ],
      "metadata": {
        "id": "6SO5St_i79ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "scpHmJuH7914"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}